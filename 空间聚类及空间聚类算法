空间聚类概念
空间聚类作为聚类分析的一个研究方向，是指将空间数据集中的对象分成由相似对象组成的类。同类中的对象间具有较高的相似度，而不同类中的对象间差异较大。作为一种无监督的学习方法，空间聚类不需要任何先验知识，比如预先定义的类或带类的标号等。由于空间聚类方法能根据空间对象的属性对空间对象进行分类划分，其已经被广泛应用在城市规划、环境监测、地震预报等领域，发挥着较大的作用。同时，空间聚类也一直都是空间数据挖掘研究领域中的一个重要研究分支。目前，己有许多文献资料提出了针对不同数据类型的多种空间聚类算法，一些著名的软件，如WEAK、SPSS、SAS等软件中已经集成了各种聚类分析软件包。
1 空间数据的复杂性
空间聚类分析的对象是空间数据。由于空间数据具有空间实体的位置、大小、形状、方位及几何拓扑关系等信息，使得空间数据的存储结构和表现形式比传统事务型数据更为复杂，空间数据的复杂特性表现：
(1)空间属性间的非线性关系。由于空问数据中蕴含着复杂的拓扑关系，因此，空间属性间呈现出一种非线性关系。这种非线性关系不仅是空间数据挖掘中需要进一步研究的问题，也是空问聚类所面临的难点之一。
(2)空间数据的尺度特征。空间数据的尺度特征足指在不同的层次上，空间数据所表现出来的特征和规律都不尽相同。虽然在空间信息的概化和细化过程中可以利用此特征发现整体和局部的不同特点，但对空间聚类任务来说，实际上是增加了空间聚类的难度。
(3) 间信息的模糊性。空间信息的模糊性足指各种类型的窄问信息中，包含大量的模糊信息，如空问位置、 间关系的模糊性，这种特性最终会导致空间聚类结果的不确定性。
(4)空间数据的高维度。空问数据的高维度性是指空间数据的属性(包括空间属性和非空间属性)个数迅速增加，比如在遥感领域，获取的空间数据的维度已经快速增加到几十甚至上百个，这会给空间聚类的研究增加很大的困难。
2 空间聚类算法
目前，研究人员已经对空间聚类问题进行了较为深入的研究，提出了多种算法。根据空间聚类采用的不同思想，空间聚类算法主要可归纳为以下几种：基于划分的聚类算法、基于层次的聚类算法、基于密度的聚类算法、基于网格的聚类算法、基于模型的聚类算法以及其它形式的聚类算法，如图l所示。
(1)基于划分的聚类
基于划分的聚类方法是最早出现并被经常使用的经典聚类算法。其基本思想是：在给定的数据集随机抽取n个元组作为n个聚类的初始中心点，然后通过不断计算其它数据与这几个中心点的距离(比如欧几里得距离)，将每个元组划分到其距离最近的分组中，从而完成聚类的划分。由于基于划分的聚类方法比较容易理解，且易实现，目前其已被广泛的弓l入到空间聚类中，用于空间数据的分类。其中最为常用的几种算法是：k一平均(k-means)算法、kl中心点(k—medoids)算法和EM(expectation maximization)算法。k一平均算法 ’使用每个聚类中所有对象的平均值作为该聚类的中心；k一中心点算法 I贝0选用簇中位置最中心的对象作为聚类中心；而EM算法“’则采用一个平均概率分布和一个d×d协方差矩阵来表示一个聚类。除上述3种算法外，也出现了众多的基于上述算法的变异算法，如基于选择的方法(CLARA)、基于随机搜索的方法(cLARANs)等。
(2)基于层次的聚类
基于层次的聚类方法就是将数据对象组成一棵聚类的树。根据层次的分解方向，分为凝聚法和分裂法。凝聚法最初假定数据集中的每个对象都为一个单独的类，然后通过不
断合并相近的对象，直到满足条件为止；分裂法同凝聚法的分解方向相反，其开始假设所有的对象都在一个类中，之后不断进行分裂，直到满足条件为止。由于一个类一旦分裂或凝聚就不能撤消，因此基于层次的算法的灵活性较差，故很少有纯粹的层次算法，层次方法往往和其它方法相结合进行聚类。代表性算法有：CURE算法、CHAMELEON算法。CURE(clustering using representatives)算法 是一种新颖的层次算法，它采取随机取样和划分相结合的方法：一个随机样本首先被划分，每个划分被局部聚类，最后把每个划分中产生的聚类结果用层次聚类的方法进行聚类。较好的解决了偏好球形和相似大小的问题，在处理孤立点时也更加健壮。CHAMELEON(hierarchical clustering using dynamic modeling)算法 的主要思想是首先使用图划分算法将数据对象聚类为大量相对较小的子类，其次使用凝聚的层次聚类算法反复地合并子类来找到真正的结果类。CHAMELEON算法是在CURE等算法的基础上改进而来，能够有效的解决CURE等算法的问题。
(3)基于密度的聚类
基于密度的聚类算法主要特点在于其使用区域密度作为划分聚类的依据，其认为只要数据空间区域的密度超过了预先定义的阀值，就将其添加到相近的聚类中。这种方法不同于各种各样基于距离的聚类算法，其优点在于能够发现任意形状的聚类，从而克服基于距离的方法只能发现类圆形聚类的缺点。代表性算法有：DBSCAN算法、OPTICS算法、DE—NCLUE算法等。DBSCAN(density based spatial clustering ofapplications withnoise)算法” 将聚类定义为基于密度可达性最大的密度相连对象的集合。聚类分析时，它必须输入参数￡、MinPts，其中，￡是给定对象的半径，MinPts是一个对象的￡邻域内包含的最少对象数目。检查一个对象的￡邻域的密度是否较大，即一定距离￡内数据点的个数是否超过MinPts来确定是否建立一个以该对象为核心对象的新类，再合并密度可达类。尽管DBSCAN算法能对任意形状的数据集进行聚类。但它仍需要用户输入参数￡和MinPts，而聚类结果对这两个参数的值又非常敏感。这事实上是将选择参数的任务留给了用户，而在实际中，用户很难准确确定合适的参数值，这往往导致聚类结果的偏差。因此，为了克服上述问题，人们提出了一种基于DBSCAN的改进算法OPTICS(ordering points to identify theclustering structure) 。OPTICS算法为自动和交互的聚类分析计算一个聚类次序，这个次序反映了数据基于密度的聚类结构，并且能够使用图形或其它可视化的方法表示。DENCLUE(density—basedclustering)算法 也是一种基于密度分布的聚类方法，概括了包括划分法、层次法等多种聚类方法，能够处理包含大量噪音的聚类，并且其执行效率要远远高于DBSCAN算法。
(4)基于网格的聚类基于网格的聚类主要思想是将空间区域划分若干个具有层次结构的矩形单元，不同层次的单元对应于不同的分辨率网格，把数据集中的所有数据都映射到不同的单元网格中，算法所有的处理都是以单个单元网格为对象，其处理速度要远比以元组为处理对象的效率要高的多。代表性算法有：STING算法、CLIQUE算法、WAVE．CLUSTER算法等。STING(statistical information gnd)算法“ 首先将空间区域划分为若干矩形单元，这些单元形成一个层次结构，每个高层单元被划分为多个低一层的单元。单元中预先计算并存储属性的统计信息，高层单元的统计信息可以通过底层单元计算获得。这种算法的优点是效率很高，而且层次结构有利于并行处理和增量更新；其缺点是聚类的边界全部是垂直或是水平的，与实际情况可能有比较大的差别，影响聚类的质量。WaveCluster(clustering using wavelet transformation)算法 “是一种采用小波变换的聚类方法。其首先使用多维数据网格结构汇总区域空间数据，用多维向量空间表示多维空间中的数据对象，然后使用小波变换方法对特征空间进行处理，发现特征空间中的稠密区域。最终通过多次小波变换，获得多分辨率的聚类。CLIQuE(clustefinginquest)算法“ 综合了基于密度和基于网格的聚类方法。其主要思想是将多维数据空间划分为多个矩形单元，通过计算每一个单元中数据点中全部数据点的比例的方法确定聚类。其优点是能够有效处理高维度的数据集，缺点是聚类的精度有可能会降低。
(5)基于模型的聚类
基于模型的聚类主要思想是假设数据集中的数据分布符合特定的数学模型，通过数学模型来发现聚类。主要有两种基于模型的方法：一种是统计学的方法，代表性算法是COB—WEB算法：另一种是神经网络的方法，代表性的算法是竞争学习算法。COBWEB算法m 是一种增量概念聚类算法。这种算法不同于传统的聚类方法，它的聚类过程分为两步：首先进行聚类，然后给出特征描述。因此，分类质量不再是单个对象的函数，而且也加入了对聚类结果的特征性描述。竞争学习算法” 属于神经网络聚类。它采用若干个单元的层次结构，以一种“胜者全取”的方式对系统当前所处理的对象进行竞争。
(6)其它方法的聚类
除了上述5种空间聚类算法外，研究人员根据空间聚类的要求，提出了多种结合其它思想的空间聚类方法。影响较大的有遗传空间聚类和带约束的空间聚类算法。其中，遗传空间聚类是模仿生物进化过程中的自然选择和进化机制，通过基因编码、遗传、变异和交叉等操作，来实现空间聚类的一种算法，是一种基于群体的全局随机优化算法：而带约束的空间聚类算法则是为了解决空间聚类中所面临的空间障碍问题而产生的，如城市中的河流、湖泊等障碍，各居民点并非沿直线，而是沿着一定的道路或网络到达簇中心等情况，如果在实际分析中不考虑这些障碍，获得的聚类结果必然与实际情况有较大的误差，而带约束的空间聚类正是解决上述问题的有效算法。
3 空间聚类质量评价方法
空间聚类作为聚类的一个研究分支，其过程是一个寻找最优划分的过程，即根据聚类终止条件不断对划分进行优化，最终得到最优解。由于空间聚类是一种无监督的学习方法，事先没有任何先验知识，因此，需要一定的措施或方法对的空间聚类结果进行有效性验证和质量评价。本文主要从内部度量和外部度量两个方面对空间聚类质量进行评价。
3．1 内部度量
空间聚类的内部度量原则主要有两个：聚类内部距离和聚类间的距离。聚类内部距离是指聚类内部问对象的平均距离，它反映了聚类的紧凑性和聚类算法的有效性；而聚类间的距离是指两个聚类间所有会话的平均距离。对于良好的聚类算法来说，聚类内部距离应较小，聚类问的距离应较远。
(1)聚类间距离
假设n个空间对象被聚类为 ∈K)个簇，定义聚类间距离为所有分中心(每个簇的均值)到全域中心(所有空间对象均值)的距离之和__L= I m 一聊I式中，L—— 聚类间距离，m—— 全部空间对象的均值，mi— —簇C。所含空间对象的均值， — — 聚类的个数，l(f∈K，K— —聚类区间。
(2)聚类内部距离
假设n个空间对象被聚类为I(r个簇，定义聚类内部距离为所有聚类内部距离的总和(其中每个聚类的内部距离为该聚类所有空间对象到其中心的距离之和)D=ΣΣIp—m l其中，D— — 类内距离；P—— 任⋯ 空间研究对象，m．— — 簇C。所含空间对象的均值。
3．2 外部度量“
对聚类质量的评价，除了内部度量方法外，还有外部度量方法。外部度量方法不同于内部度量方法，其主要从当前分类是正确的分类的角度出发，衡量聚类质量的好坏。外部度量有两种方法：纯净度和F．measure熵。
(1)纯净度
纯净度定义为已知正确类符号f∈ 标识为该类的数据占整个簇的比例，即Purity(Ck)=max其中， 中类标识的数目，簇N —— 该簇中标识为t的数目。而整个聚类结果的纯净度为所有簇的纯净度的均值，表示为0= 姜⋯等其中，M — — 簇的数目，N — CL中类标识的数目，簇N — —该簇中标识为t的数目。
(2)F—meas~e熵
F—meas~e熵采用信息检索的准确率和查全率的思想。数据所属的类t看作是集合N 中等待查询的项； 由算法产生的簇C 看作是集合N 中检索的项：N 是簇C 中类t的数量。对于类t和簇C 的准确率和查全率分别是肌c( )： Ntk Pc(f，G)：V相应的F—measure是Fmeas(t,如果b=1，那么Prec(t，C )和Rec(t，C )的权重足一样的。对于整个划分的F一值
c)=Σ—1 ~1 max( 阳 (f，c^))
